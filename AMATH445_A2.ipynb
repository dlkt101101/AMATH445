{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5n+8nc5LeTGbOCBsLmNGN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlkt101101/AMATH445/blob/main/AMATH445_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AMATH 445\n",
        "## Assignment 2\n",
        "Prepared by: Darren Alexander Lam Kin Teng (20977843)"
      ],
      "metadata": {
        "id": "7UdlejXUUeTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "AeTzGVgNUsLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "czX5vT9IUN1z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import ReLU, Tanh\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from itertools import product\n",
        "from sklearn.metrics import classification_report, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/A2Q1_data_regression.pkl', 'rb') as file:\n",
        "  data_regression = pickle.load(file)\n",
        "\n",
        "with open('/content/A2Q1_data.pkl', 'rb') as file:\n",
        "  data_classification = pickle.load(file)"
      ],
      "metadata": {
        "id": "F_A-5T_QWFna"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_regression.keys(), data_classification.keys())"
      ],
      "metadata": {
        "id": "pVtr6NPjf3pG",
        "outputId": "6e09633c-f533-44ae-efdd-fd22791ca30a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['X_train', 'X_test', 'y_train', 'y_test']) dict_keys(['X_train', 'X_test', 'y_train', 'y_test'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# regression\n",
        "X_train_regression = data_regression['X_train']\n",
        "y_train_regression = data_regression['y_train']\n",
        "X_test_regression = data_regression['X_test']\n",
        "y_test_regression = data_regression['y_test']\n",
        "\n",
        "# classification\n",
        "X_train_classification = data_classification['X_train']\n",
        "y_train_classification = data_classification['y_train']\n",
        "X_test_classification = data_classification['X_test']\n",
        "y_test_classification = data_classification['y_test']"
      ],
      "metadata": {
        "id": "Oca58XKFfoMf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking Regression dataset split:')\n",
        "print(X_train_regression.shape[0]/(X_train_regression.shape[0]+X_test_regression.shape[0]))\n",
        "\n",
        "print('Checking Classification dataset split:')\n",
        "print(X_train_classification.shape[0]/(X_train_classification.shape[0]+X_test_classification.shape[0]))"
      ],
      "metadata": {
        "id": "B8hiopJzf_Pr",
        "outputId": "1c70198f-f658-49a9-e3a2-c67ec7e80ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking Regression dataset split:\n",
            "0.847457627118644\n",
            "Checking Classification dataset split:\n",
            "0.847457627118644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development"
      ],
      "metadata": {
        "id": "eKHgUhlGqwWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There will only be one node for both cases of binary classification and regression.\n",
        "\n",
        "The input layer will contain the same number of nodes as our explanatory variables.\n",
        "\n",
        "The number of neurons per hidden layer is based on a rule of thumb:\n",
        "$Neurons = \\frac{2}{3}(\\text{neurons in input layer})+1$\n",
        "(https://www.heatonresearch.com/2017/06/01/hidden-layers.html)"
      ],
      "metadata": {
        "id": "QwhepZx5lIys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bool_cols_class = X_train_classification.select_dtypes(include='bool').columns\n",
        "X_train_classification[bool_cols_class] = X_train_classification[bool_cols_class].astype(int)\n",
        "X_test_classification[bool_cols_class] = X_test_classification[bool_cols_class].astype(int)\n",
        "\n",
        "bool_cols_regress = X_train_regression.select_dtypes(include='bool').columns\n",
        "X_train_regression[bool_cols_regress] = X_train_regression[bool_cols_regress].astype(int)\n",
        "X_test_regression[bool_cols_regress] = X_test_regression[bool_cols_regress].astype(int)"
      ],
      "metadata": {
        "id": "oVgBNmSzoRVa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_regression = X_train_regression.shape[1]\n",
        "input_layer_classification = X_train_classification.shape[1]\n",
        "# N_neurons_regression = math.floor(2/3 * input_layer_regression) + 1\n",
        "# N_neurons_classification = math.floor(2/3 * input_layer_classification) + 1\n",
        "N_neurons_regression = 10\n",
        "N_neurons_classification = 10\n",
        "output_layer = 1\n",
        "\n",
        "EPOCHS = 500"
      ],
      "metadata": {
        "id": "CRqSih_-sVSE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, problem=\"classification\", activation_function='relu'):\n",
        "        super().__init__()\n",
        "        self.problem = problem\n",
        "        self.activation_function_type = activation_function\n",
        "\n",
        "        if problem == \"classification\":\n",
        "          INPUT_SIZE, N_NEURONS = input_layer_classification, N_neurons_classification\n",
        "        elif problem == \"regression\":\n",
        "          INPUT_SIZE, N_NEURONS = input_layer_regression, N_neurons_regression\n",
        "        else:\n",
        "          print(\"Invalid problem. Problem must be 'regression' or 'classification'.\")\n",
        "\n",
        "        # building the neural network\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(INPUT_SIZE, N_NEURONS),\n",
        "            nn.BatchNorm1d(N_NEURONS),\n",
        "            Tanh() if self.activation_function_type in ['mixed', 'tanh'] else ReLU(),\n",
        "            nn.Linear(N_NEURONS, N_NEURONS),\n",
        "            nn.BatchNorm1d(N_NEURONS),\n",
        "            ReLU() if self.activation_function_type in ['mixed', 'relu'] else Tanh(),\n",
        "            nn.Linear(N_NEURONS, N_NEURONS),\n",
        "            nn.BatchNorm1d(N_NEURONS),\n",
        "            ReLU() if self.activation_function_type in ['mixed', 'tanh'] else Tanh(),\n",
        "            nn.Linear(N_NEURONS, output_layer))\n",
        "\n",
        "    def forward(self, x):\n",
        "      logits = self.layers(x)\n",
        "      if self.problem == \"classification\":\n",
        "        return torch.sigmoid(logits)\n",
        "      return logits"
      ],
      "metadata": {
        "id": "BUOKcKJRvT9c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits = 5, random_state=123, shuffle=True)"
      ],
      "metadata": {
        "id": "zwVspNZ8Hha_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model_cv(problem_type='classification', learning_rate = [0.0001, 0.001],\n",
        "                            momentum = [0.0, 0.9], activation_function = ['relu', 'tanh', 'mixed']):\n",
        "\n",
        "  X_raw = X_train_classification if problem_type == 'classification' else X_train_regression\n",
        "  y_raw = y_train_classification if problem_type == 'classification' else y_train_regression\n",
        "\n",
        "  X = torch.tensor(X_raw.values, dtype=torch.float32)\n",
        "  y = torch.tensor(y_raw.values, dtype=torch.float32)\n",
        "\n",
        "  parameter_grid = {'lr' : learning_rate,\n",
        "                    'mom' : momentum,\n",
        "                    'act' : activation_function}\n",
        "\n",
        "  combinations = list(product(parameter_grid['lr'], parameter_grid['mom'], parameter_grid['act']))\n",
        "\n",
        "  # store the best hyper parameters\n",
        "  best_loss = math.inf\n",
        "  best_parameters = {}\n",
        "\n",
        "  for lr, mom, act in combinations:\n",
        "    losses = []\n",
        "    for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "      X_train, X_val = X[train_index], X[val_index]\n",
        "      y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "      model = NeuralNetwork(problem=problem_type, activation_function=act)\n",
        "      optimizer = optim.Adam(model.parameters(), lr=lr, betas=(mom, 0.999))\n",
        "\n",
        "      # specify the criterion for classification and regression\n",
        "      if problem_type == 'regression':\n",
        "        criterion = nn.MSELoss()\n",
        "      else:\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "      model.train()\n",
        "      for epoch in range(EPOCHS):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train.view_as(outputs))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      # model evaluation\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val.view_as(val_outputs))\n",
        "        losses.append(val_loss.item())\n",
        "\n",
        "    avg_fold_loss = np.mean(losses)\n",
        "\n",
        "    if avg_fold_loss < best_loss:\n",
        "      best_loss = avg_fold_loss\n",
        "      best_parameters = {'lr' : lr,\n",
        "                         'mom' : mom,\n",
        "                         'act' : act}\n",
        "\n",
        "  return (best_loss, best_parameters)\n"
      ],
      "metadata": {
        "id": "zN5lcIjOJTFP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_params = train_evaluate_model_cv(problem_type='classification')"
      ],
      "metadata": {
        "id": "wFNMuJU5cDx0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regress_params = train_evaluate_model_cv(problem_type='regression')"
      ],
      "metadata": {
        "id": "Gd69z_SjwhfH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we get the results from our deep learning models for both regression and classification along with their best parameters."
      ],
      "metadata": {
        "id": "oUlwPCmspiQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKbbCXGDpEnu",
        "outputId": "c534328a-e374-4a0e-e74f-ffea40f01067"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.6477210402488709), {'lr': 0.0001, 'mom': 0.0, 'act': 'tanh'})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regress_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpqXAo8kpgKd",
        "outputId": "c6863642-853e-4194-e9cd-7efce89dcdb2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(5160.131640625), {'lr': 0.001, 'mom': 0.0, 'act': 'mixed'})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Model"
      ],
      "metadata": {
        "id": "2-ZlirgXsIZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr_class = class_params[1]['lr']\n",
        "best_mom_class = class_params[1]['mom']\n",
        "best_act_class = class_params[1]['act']\n",
        "\n",
        "final_model_class = NeuralNetwork(problem=\"classification\", activation_function=best_act_class)\n",
        "optimizer_class = optim.Adam(final_model_class.parameters(), lr=best_lr_class, betas=(best_mom_class, 0.999))\n",
        "criterion_class = nn.BCELoss()"
      ],
      "metadata": {
        "id": "6HCRGF2Cx_nO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr_regress = regress_params[1]['lr']\n",
        "best_mom_regress = regress_params[1]['mom']\n",
        "best_act_regress = regress_params[1]['act']\n",
        "\n",
        "final_model_regress = NeuralNetwork(problem=\"regression\", activation_function=best_act_regress)\n",
        "optimizer_regress = optim.Adam(final_model_regress.parameters(), lr=best_lr_regress, betas=(best_mom_regress, 0.999))\n",
        "criterion_regress = nn.MSELoss()"
      ],
      "metadata": {
        "id": "kqBIjYoVyLfF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_c = torch.tensor(X_train_classification.values, dtype=torch.float32)\n",
        "y_train_c = torch.tensor(y_train_classification.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test_c = torch.tensor(X_test_classification.values, dtype=torch.float32)\n",
        "y_test_c = torch.tensor(y_test_classification.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_train_r = torch.tensor(X_train_regression.values, dtype=torch.float32)\n",
        "y_train_r = torch.tensor(y_train_regression.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test_r = torch.tensor(X_test_regression.values, dtype=torch.float32)\n",
        "y_test_r = torch.tensor(y_test_regression.values, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "oQ-xNnrTzA4N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the models"
      ],
      "metadata": {
        "id": "MhbRIRpk1B3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training classification model\n",
        "final_model_class.train()\n",
        "for epoch in range(EPOCHS):\n",
        "  optimizer_class.zero_grad()\n",
        "  outputs_class = final_model_class(X_train_c)\n",
        "  loss_class = criterion_class(outputs_class, y_train_c)\n",
        "  loss_class.backward()\n",
        "  optimizer_class.step()"
      ],
      "metadata": {
        "id": "OO8_Yzpp0ate"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training regression model\n",
        "final_model_regress.train()\n",
        "for epoch in range(EPOCHS):\n",
        "  optimizer_regress.zero_grad()\n",
        "  outputs_regress = final_model_regress(X_train_r)\n",
        "  loss_regress = criterion_regress(outputs_regress, y_train_r)\n",
        "  loss_regress.backward()\n",
        "  optimizer_regress.step()"
      ],
      "metadata": {
        "id": "FiNXQBD50nMw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting with the models"
      ],
      "metadata": {
        "id": "ogmrSXzT1Dsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_class.eval()\n",
        "with torch.no_grad():\n",
        "    # Get raw probabilities\n",
        "    raw_probs = final_model_class(X_test_c)\n",
        "    preds_class = (raw_probs > 0.5).float()\n",
        "\n",
        "y_true_class = y_test_c.numpy()\n",
        "y_pred_class = preds_class.numpy()"
      ],
      "metadata": {
        "id": "1MSiNc6D0_t4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression prediction\n",
        "final_model_regress.eval()\n",
        "with torch.no_grad():\n",
        "    preds_regress = final_model_regress(X_test_r)\n",
        "\n",
        "y_true_regress = y_test_r.numpy()\n",
        "y_pred_regress = preds_regress.numpy()"
      ],
      "metadata": {
        "id": "Ys94rxYi1J-V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating final models"
      ],
      "metadata": {
        "id": "n4IwWNTp2Rv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_true_class, y_pred_class)\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "qkhtVpJZ2kMm",
        "outputId": "bde7b82d-0ac7-45b5-cb60-e7f0d51d1641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.67      0.69        36\n",
            "         1.0       0.40      0.44      0.42        18\n",
            "\n",
            "    accuracy                           0.59        54\n",
            "   macro avg       0.55      0.56      0.55        54\n",
            "weighted avg       0.60      0.59      0.60        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_true_regress, y_pred_regress)\n",
        "print('The regression NN has a MSE: {}'.format(round(mse, 6)))"
      ],
      "metadata": {
        "id": "ged5Yvsr2Qpy",
        "outputId": "5c83d109-1aa8-4d00-fe73-c04f8257f6f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The regression NN has a MSE: 5369.636719\n"
          ]
        }
      ]
    }
  ]
}